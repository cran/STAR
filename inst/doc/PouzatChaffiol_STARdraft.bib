% This file was created with JabRef 2.3.1.
% Encoding: ISO8859_1

@BOOK{AbelsonEtAl_1996,
  title = {Structure and {I}nterpretation of {C}omputer {P}rograms},
  publisher = {MIT Press},
  year = {1996},
  author = {Abelson, Harold and Sussman, Gerald Jay and Sussman, Julie},
  edition = {second edition},
  note = {Book website:\url{http://mitpress.mit.edu/sicp/full-text/book/book.html}},
  __markedentry = {[xtof]},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://mitpress.mit.edu/sicp/full-text/book/book.html}
}

@BOOK{BatesWatts_1988,
  title = {Nonlinear Regression Analysis and Its Applications},
  publisher = {Wiley},
  year = {1988},
  author = {Bates, D. M. and Watts, D. G.},
  __markedentry = {[xtof]},
  owner = {xtof},
  timestamp = {2008.03.14}
}

@ARTICLE{Brillinger_1988b,
  author = {D. R. Brillinger},
  title = {Maximum likelihood analysis of spike trains of interacting nerve
	cells.},
  journal = {Biol Cybern},
  year = {1988},
  volume = {59},
  pages = {189--200},
  number = {3},
  __markedentry = {[xtof]},
  abstract = {Suppose that a neuron is firing spontaneously or that it is firing
	under the influence of other neurons. Suppose that the data available
	are the firing times of the neurons present. An "integrate several
	inputs and fire" model is developed and studied empirically. For
	the model a neuron's firing occurs when an internal state variable
	crosses a random threshold. This conceptual model leads to maximum
	likelihood estimates of internal quantities, such as the postsynaptic
	potentials of the measured influencing neurons, the membrane potential,
	the absolute threshold and also estimates of derived quantities such
	as the strength-duration curve and the recovery process of the threshold.
	The model's validity is examined via an estimate of the conditional
	firing probability. The approach appears useful for estimating biologically
	meaningful parameters, for examining hypotheses re these parameters,
	for understanding the connections present in neural networks and
	for aiding description and classification of neurons and synapses.
	Analyses are presented for a number of data sets collected for the
	sea hare, Aplysia californica, by J. P. Segundo. Both excitatory
	and inhibitory examples are provided. The computations were carried
	out via the Glim statistical package. An example of a Glim program
	realizing the work is presented in the Appendix.},
  file = {Brillinger_1988b.pdf:Spike_Train_Analysis/Brillinger_1988b.pdf:PDF},
  keywords = {Animals; Aplysia; Cybernetics; Electrophysiology; Models, Neurological;
	Models, Theoreti; Nerve Net; Neurons; cal},
  owner = {xtof},
  pmid = {3179344},
  review = {Very good paper.
	
	The conditional intensity (CI) is estimated from discretized trains.
	
	A binomial model with a probit (somewhat justified) link function
	is used.
	
	Neurons own effects are model as cubic polynoms.
	
	Interactions are estimated with step functions.
	
	The two previous factors contribute linearly on the predictor scale.
	
	GLIM is used.
	
	Goodness of fit tests are used.},
  timestamp = {2008.03.14}
}

@ARTICLE{BrillingerEtAl_1976,
  author = {D. R. Brillinger and H. L. Bryant and J. P. Segundo},
  title = {Identification of synaptic interactions.},
  journal = {Biol Cybern},
  year = {1976},
  volume = {22},
  pages = {213--228},
  number = {4},
  month = {May},
  __markedentry = {[xtof]},
  file = {BrillingerEtAl_1976.pdf:Spike_Train_Analysis/BrillingerEtAl_1976.pdf:PDF},
  keywords = {Action Potentials; Humans; Models, Neurological; Snails; Synapses},
  owner = {xtof},
  pmid = {953079},
  timestamp = {2008.03.14}
}

@BOOK{BurnhamAnderson_2002,
  title = {M{ODEL} {SLECTION} {AND} {MULTIMODEL} {INFERENCE}. {A} {P}ractical
	{I}nformation-{T}heoretic {A}pproach.},
  publisher = {Springer},
  year = {2002},
  author = {Burnham, Kenneth P. and Anderson, David R.},
  edition = {2nd},
  __markedentry = {[xtof]},
  owner = {xtof},
  timestamp = {2008.03.14}
}

@ARTICLE{Chambers_1999,
  author = {Chambers, John},
  title = {Computing with {D}ata: {C}oncepts and {C}hallenges},
  journal = {The American Statistician},
  year = {1999},
  volume = {53},
  pages = {73--84},
  number = {1},
  note = {Available from: \url{http://cm.bell-labs.com/stat/doc/Neyman98.ps}},
  __markedentry = {[xtof]},
  abstract = {This article examines work in "computing with data"-in computing support
	for scientific and other activities to which statisticians can contribute.
	Relevant computing techniques, besides traditional statistical computing,
	include data management, visualization, interactive languages, and
	user-interface design. The article emphasizes the concepts underlying
	computing with data, with emphasis on how those concepts can help
	in practical work. We look at past, present, and future: some concepts
	as they arose in the past and as they have proved valuable in current
	software; applications in the present, with one example in particular,
	to illustrate the challenges these present; and new directions for
	future research, including one exciting joint project.},
  eprint = {http://links.jstor.org/sici?sici=0003-1305%28199902%2953%3A1%3C73%3ACWDCAC%3E2.0.CO%3B2-1},
  file = {Chambers_1999.pdf:R_stuff/Chambers_1999.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://cm.bell-labs.com/cm/ms/departments/sia/jmc/pub.html}
}

@BOOK{Chambers_2008,
  title = {Software for Data Analysis. Programming with R.},
  publisher = {Springer},
  year = {2008},
  author = {John M. Chambers},
  series = {Statistics and Computing},
  __markedentry = {[xtof]},
  owner = {xtof},
  timestamp = {2008.09.02}
}

@ARTICLE{Chambers_2000,
  author = {John M. Chambers},
  title = {Users, Programmers and Statistical Software},
  journal = {Journal of Computational and Graphical Statistics},
  year = {2000},
  volume = {9},
  pages = {404--422},
  number = {3},
  month = {sep},
  note = {Available from: \url{http://cm.bell-labs.com/stat/doc/jmcJCGS2000.ps}},
  __markedentry = {[xtof]},
  abstract = {Statistical software provides essential support for statisticians
	and others who are analyzing data or doing research on new statistical
	techniques. Those supported typically regard themselves as ``users''
	of the software, but as soon as they need to express their own ideas
	computationally, they in fact become ``programmers.'' Nothing is
	more important for the success of statistical software than enabling
	this transition from user to programmer, and on to gradually more
	ambitious software design. What does the user need? How can the design
	of statistical software help? This article presents a number of suggestions
	based on past experience and current research. The evolution of the
	S system reflects some of these opinions. Work on the Omegahat software
	provides a promising direction for future systems that reflect similar
	motivations.},
  file = {Chambers_2000.pdf:R_stuff/Chambers_2000.pdf:PDF},
  keywords = {Computing environments; Data analysis; Object-oriented programming;
	Statistical computing},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://cm.bell-labs.com/cm/ms/departments/sia/jmc/pub.html}
}

@BOOK{ChambersEtAl_1983,
  title = {GRAPHICAL METHODS FOR DATA ANALYSIS},
  publisher = {Wadsworth \& Brooks/Cole},
  year = {1983},
  author = {John M. Chambers and William S. Cleveland and Beat Kleiner and Paul
	A. Tukey},
  __markedentry = {[xtof]},
  owner = {xtof},
  timestamp = {2008.03.14}
}

@BOOK{CoxLewis_1966,
  title = {The Statistical Analysis of Series of Events},
  publisher = {John Wiley \& Sons},
  year = {1966},
  author = {Cox, D. R. and Lewis, P. A. W.},
  __markedentry = {[xtof]},
  owner = {xtof},
  timestamp = {2008.03.14}
}

@ARTICLE{CravenWahba_1979,
  author = {Peter Craven and Grace Wahba},
  title = {Smoothing Noisy Data with Spline Functions. Estimating the Correct
	Degree of Smoothing by the Method of Generalized Cross-Validation.},
  journal = {Numerische Mathematik},
  year = {1979},
  volume = {31},
  pages = {377--404},
  note = {Available at: \url{http://resolver.sub.uni-goettingen.de/purl?GDZPPN00117486X}},
  __markedentry = {[xtof]},
  file = {CravenWahba_1979.pdf:SmoothAndKernel/CravenWahba_1979.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://resolver.sub.uni-goettingen.de/purl?GDZPPN00117486X}
}

@ARTICLE{CumminsEtAl_2001,
  author = {Cummins, David J. and Filloon, Tom G. and Nychka, Douglas},
  title = {Confidence Intervals for Nonparametric Curve Estimates: Toward More
	Uniform Pointwise Coverage},
  journal = {Journal of the American Statistical Association},
  year = {2001},
  volume = {96},
  pages = {233--246},
  number = {453},
  month = {mar},
  __markedentry = {[xtof]},
  abstract = {Numerous nonparametric regression methods exist that yield consistent
	estimators of function curves. Often, one is also interested in constructing
	confidence intervals for the unknown function. When a function estimate
	is based on a single global smoothing parameter the resulting confidence
	intervals may hold their desired confidence level 1 -$\alpha$ on
	average but because bias in nonparametric estimation is not uniform,
	they do not hold the desired level uniformly at all design points.
	Most research in this area has focused on mean squared error properties
	of the estimator, for example MISE, itself a global measure. In addition,
	measures like MISE are one step removed from the practical issue
	of coverage probability. Recent work that focuses on coverage probability
	has considered only coverage in an average sense, ignoring the important
	issue of uniformity of coverage across the design space. To deal
	with this problem, a new estimator is developed which uses a local
	cross-validation criterion (LCV) to determine a separate smoothing
	parameter for each design point. The local smoothing parameters are
	then used to compute the point estimators of the regression curve
	and the corresponding pointwise confidence intervals. Incorporation
	of local information through the new method is shown, via Monte Carlo
	simulation, to yield more uniformly valid pointwise confidence intervals
	for nonparametric regression curves. Diagnostic plots are developed
	(Breakout Plots) to visually inspect the degree of uniformity of
	coverage of the confidence intervals. The approach, here applied
	to cubic smoothing splines, easily generalizes to many other nonparametric
	regression estimators. The improved curve estimation is not a solely
	theoretical improvement such as providing an estimator that has a
	faster EASE convergence rate but shows its worth empirically by yielding
	improved coverage probabilities through reliable pointwise confidence
	intervals.},
  copyright = {Copyright 2001 American Statistical Association},
  file = {CumminsEtAl_2001.pdf:SmoothAndKernel/CumminsEtAl_2001.pdf:PDF},
  group = {Theory and Methods},
  issn = {0162-1459},
  jstor_articletype = {Full Length Article},
  jstor_date = {200103},
  jstor_formatteddate = {Mar., 2001},
  keywords = {Coverage Probability, Local Cross-Validation, Nonparametric Regression,
	Pointwise Confidence Intervals, Smoothing Splines},
  owner = {xtof},
  publisher = {American Statistical Association},
  timestamp = {2008.03.14},
  url = {http://links.jstor.org/sici?sici=0162-1459%28200103%2996%3A453%3C233%3ACIFNCE%3E2.0.CO%3B2-T}
}

@BOOK{Devroye_1986,
  title = {Non-Uniform Random Variate Generation},
  publisher = {Springer-Verlag},
  year = {1986},
  author = {Devroye, Luc},
  note = {Available at: \url{http://cg.scs.carleton.ca/~luc/rnbookindex.html}},
  __markedentry = {[xtof]},
  file = {preface.pdf:MonteCarlo_RandomNumbers/DevroyeBook/preface.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://cg.scs.carleton.ca/~luc/rnbookindex.html}
}

@ARTICLE{EscolaEtAl_2008,
  author = {Escola, Ricardo and Pouzat, Christophe and Chaffiol, Antoine and
	Yvert, Blaise and Magnin, Isabelle E. and Guillemaud, Regis},
  title = {SIMONE : A Neural Simulator to Test MEA-embedded Algorithms.},
  journal = {IEEE Transactions on Neural and Rehabilitation Engineering},
  year = {2008},
  volume = {16},
  pages = {149--160},
  number = {2},
  month = {apr},
  __markedentry = {[xtof]},
  abstract = {Contemporary multielectrode arrays (MEAs) used to record extracellular
	activity from neural tissues can deliver data at rates on the order
	of 100 Mbps. Such rates require efficient data compression and/or
	preprocessing algorithms implemented on an application specific integrated
	circuit (ASIC) close to the MEA. We present SIMONE (Statistical sIMulation
	Of Neuronal networks Engine), a versatile simulation tool whose parameters
	can be either fixed or defined by a probability distribution. We
	validated our tool by simulating data recorded from the first olfactory
	relay of an insect. Different key aspects make this tool suitable
	for testing the robustness and accuracy of neural signal processing
	algorithms (such as the detection, alignment, and classification
	of spikes). For instance, most of the parameters can be defined by
	a probabilistic distribution, then tens of simulations may be obtained
	from the same scenario. This is especially useful when validating
	the robustness of the processing algorithm. Moreover, the number
	of active cells and the exact firing activity of each one of them
	is perfectly known, which provides an easy way to test accuracy.},
  doi = {10.1109/TNSRE.2007.914467},
  owner = {xtof},
  timestamp = {2008.03.14}
}

@TECHREPORT{GentlemanTempleLang_2004,
  author = {Gentleman, Robert and Temple Lang, Duncan},
  title = {Statistical {A}nalyses and {R}eproducible {R}esearch},
  institution = {Bioconductor Project Working Papers},
  year = {2004},
  type = {Working Paper},
  number = {2},
  month = {29 } # may,
  note = {Available at: \url{http://www.bepress.com/bioconductor/paper2/}},
  __markedentry = {[xtof]},
  abstract = {For various reasons, it is important, if not essential, to integrate
	the computations and code used in data analyses, methodological descriptions,
	simulations, etc. with the documents that describe and rely on them.
	This integration allows readers to both verify and adapt the statements
	in the documents. Authors can easily reproduce them in the future,
	and they can present the document's contents in a different medium,
	e.g. with interactive controls. This paper describes a software framework
	for authoring and distributing these integrated, dynamic documents
	that contain text, code, data, and any auxiliary content needed to
	recreate the computations. The documents are dynamic in that the
	contents, including figures, tables, etc., can be recalculated each
	time a view of the document is generated. Our model treats a dynamic
	document as a master or ``source'' document from which one can generate
	different views in the form of traditional, derived documents for
	different audiences. We introduce the concept of a compendium as
	both a container for the different elements that make up the document
	and its computations (i.e. text, code, data, ...), and as a means
	for distributing, managing and updating the collection. The step
	from disseminating analyses via a compendium to reproducible research
	is a small one. By reproducible research, we mean research papers
	with accompanying software tools that allow the reader to directly
	reproduce the results and employ the methods that are presented in
	the research paper. Some of the issues involved in paradigms for
	the production, distribution and use of such reproducible research
	are discussed.},
  eprint = {http://www.bepress.com/bioconductor/paper2/},
  file = {:Reproducible_Research/GentlemanLang_2004.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://www.bepress.com/bioconductor/paper2/}
}

@ARTICLE{GersteinKiang_1960,
  author = {Gerstein, George L. and Kiang, Nelson Y.-S.},
  title = {An Approach to the Quantitative Analysis of Electrophysiological
	Data from Single Neurons},
  journal = {Biophysical Journal},
  year = {1960},
  volume = {1},
  pages = {15--28},
  number = {1},
  month = sep,
  note = {Available form: \url{http://www.pubmedcentral.nih.gov/articlerender.fcgi?tool=pubmed&pubmedid=13704760}},
  __markedentry = {[xtof]},
  abstract = {The application of a digital computer to the processing of data from
	single neurons is described. Examples from experimental data are
	presented to demonstrate the usefulness of certain types of computations.
	These methods are placed in a descriptive mathematical framework.
	Other easily attainable computations are suggested.},
  file = {GersteinKiang_1960.pdf:Spike_Train_Analysis/GersteinKiang_1960.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?tool=pubmed&pubmedid=13704760}
}

@ARTICLE{Gu_2008,
  author = {Gu, Chong},
  title = {Smoothing noisy data via regularization: statistical perspectives},
  journal = {Inverse Problems},
  year = {2008},
  volume = {24},
  pages = {034002--},
  number = {3},
  __markedentry = {[xtof]},
  abstract = {We present an overview of data smoothing techniques via Tikhonov regularization.
	The material is taken from the statistical literature and reflects
	the modern statistical thinking on the subject. Main topics covered
	include model construction, cross-validation, computation and data
	analytical tools.},
  doi = {10.1088/0266-5611/24/3/034002},
  file = {Gu_2008.pdf:SmoothAndKernel/Gu_2008.pdf:PDF},
  issn = {0266-5611},
  owner = {xtof},
  refid = {0266-5611-24-3-034002},
  timestamp = {2008.06.04}
}

@BOOK{Gu_2002,
  title = {Smoothing Spline Anova Models},
  publisher = {Springer},
  year = {2002},
  author = {Chong Gu},
  __markedentry = {[xtof]},
  file = {Gu_2002.pdf:SmoothAndKernel/Gu_2002.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14}
}

@ARTICLE{Gu_1992b,
  author = {Gu, Chong},
  title = {Cross-Validating Non-Gaussian Data},
  journal = {Journal of Computational and Graphical Statistics},
  year = {1992},
  volume = {1},
  pages = {169--179},
  number = {2},
  month = {jun},
  __markedentry = {[xtof]},
  abstract = {This article describes an appropriate way of implementing the generalized
	cross-validation method and some other least-squares-based smoothing
	parameter selection methods in penalized likelihood regression problems,
	and explains the rationales behind it. Simulations of limited scale
	are conducted to back up the semitheoretical analysis.},
  copyright = {Copyright 1992 American Statistical Association, Institute of Mathematical
	Statistics, and Interface Foundation of America},
  file = {Gu_1992b.pdf:SmoothAndKernel/Gu_1992b.pdf:PDF},
  issn = {1061-8600},
  jstor_articletype = {Full Length Article},
  jstor_date = {199206},
  jstor_formatteddate = {Jun., 1992},
  keywords = {Generalized cross-validation, Performance-oriented iteration, Pseudodata,
	Smoothing parameter, Unbiased risk estimate},
  owner = {xtof},
  publisher = {American Statistical Association},
  timestamp = {2008.03.14},
  url = {http://links.jstor.org/sici?sici=1061-8600%28199206%291%3A2%3C169%3ACND%3E2.0.CO%3B2-1}
}

@ARTICLE{GuXiang_2001,
  author = {Gu, Chong and Xiang, Dong},
  title = {Cross-Validating Non-Gaussian Data: Generalized Approximate Cross-Validation
	Revisited},
  journal = {Journal of Computational and Graphical Statistics},
  year = {2001},
  volume = {10},
  pages = {581--591},
  number = {3},
  month = {sep},
  __markedentry = {[xtof]},
  abstract = {This article presents an alternative derivation of the generalized
	approximate cross-validation (GACV) score of Xiang and Wahba (1996)
	for smoothing parameter selection in penalized likelihood regression.
	The new derivation suggests a simple numerical solution that is stable
	for all sample sizes. Also suggested is a variant of the score that
	can be computationally more convenient. Simple simulations are presented
	to illustrate the effectiveness of the scores.},
  copyright = {Copyright 2001 American Statistical Association, Institute of Mathematical
	Statistics, and Interface Foundation of America},
  file = {GuXiang_2001.pdf:SmoothAndKernel/GuXiang_2001.pdf:PDF},
  issn = {1061-8600},
  jstor_articletype = {Full Length Article},
  jstor_date = {200109},
  jstor_formatteddate = {Sep., 2001},
  keywords = {Kullback-Leibler loss, Penalized likelihood, Smoothing parameter},
  owner = {xtof},
  publisher = {American Statistical Association},
  timestamp = {2008.03.14},
  url = {http://links.jstor.org/sici?sici=1061-8600%28200109%2910%3A3%3C581%3ACNDGAC%3E2.0.CO%3B2-T}
}

@ARTICLE{IhakaGentleman_1996,
  author = {Ihaka, R and Gentleman, R},
  title = {R: {A} {L}anguage for {D}ata {A}nalysis and {G}raphics},
  journal = {Journal of Graphical and Computational Statistics},
  year = {1996},
  volume = {5},
  pages = {299--314},
  __markedentry = {[xtof]},
  abstract = {In this article we discuss our experience designing and implementing
	a statistical computing language. In developing this new language,
	we sought to combine what we felt were useful features from two existing
	computer languages. We feel that the new language provides advantages
	in the areas of portability, computational efficiency, memory management,
	and scoping.},
  file = {IhakaGentleman_1996.pdf:Statistics/IhakaGentleman_1996.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://links.jstor.org/sici?sici=1061-8600%28199609%295%3A3%3C299%3ARALFDA%3E2.0.CO%3B2-D}
}

@ARTICLE{Johnson_1996,
  author = {Johnson, D.H.},
  title = {Point process models of single-neuron discharges},
  journal = {J. Computational Neuroscience},
  year = {1996},
  volume = {3},
  pages = {275-299},
  number = {4},
  __markedentry = {[xtof]},
  abstract = {In most neural systems, neurons communicate via sequences of action
	potentials. Contemporary models assume that the action potentials'
	times of occurrence rather than their waveforms convey information.
	The mathematical tool for describing sequences of events occurring
	in time and/or space is the theory of point processes. Using this
	theory, we show that neural discharge patterns convey time-varying
	information intermingled with the neuron's response characteristics.
	We review the basic techniques for analyzing single-neuron discharge
	patterns and describe what they reveal about the underlying point
	process model. By applying information theory and estimation theory
	to point processes, we describe the fundamental limits on how well
	information can be represented by and extracted from neural discharges.
	We illustrate applying these results by considering recordings from
	the lower auditory pathway.},
  discloc = {/media/usbdisk-1/PaperPDF/Spike_Train_Analysis/Johnson_1996.pdf},
  eprint = {http://www-ece.rice.edu/~dhj/cv.html#publications},
  file = {Johnson_1996.pdf:Spike_Train_Analysis/Johnson_1996.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14}
}

@BOOK{Kaissling_1987,
  title = {R {H} {W}right {L}ectures on {I}nsect {O}lfaction},
  publisher = {Munich: Typographischer Betrieb, W Biering, H Numberger},
  year = {1987},
  editor = {Colbow, K.},
  author = {Kaissling, Karl-Ernst},
  __markedentry = {[xtof]},
  owner = {xtof},
  timestamp = {2008.03.14}
}

@BOOK{Kalbfleisch_1985,
  title = {Probability and {S}tatistical {I}nference. {V}olume 2: {S}tatistical
	{I}nference},
  publisher = {Springer-Verlag},
  year = {1985},
  author = {Kalbfleisch, J. G.},
  series = {Springer Texts in Statistics},
  edition = {second},
  __markedentry = {[xtof]},
  file = {Kalbfleisch_1985.pdf:MaximumLikelihood/Kalbfleisch_1985.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14}
}

@ARTICLE{KassEtAl_2003,
  author = {Robert E Kass and Val\'{e}rie Ventura and Can Cai},
  title = {Statistical smoothing of neuronal data},
  journal = {Network: Computation in Neural Systems},
  year = {2003},
  volume = {14},
  pages = {5--15},
  number = {1},
  note = {Available from: \url{http://www.stat.cmu.edu/~kass/papers/smooth.pdf}},
  __markedentry = {[xtof]},
  abstract = {The purpose of smoothing (filtering) neuronal data is to improve the
	estimation of the instantaneous firing rate. In some applications,
	scientific interest centres on functions of the instantaneous firing
	rate, such as the time at which the maximal firing rate occurs or
	the rate of increase of firing rate over some experimentally relevant
	period. In others, the instantaneous firing rate is needed for probability-based
	calculations. In this paper we point to the very substantial gains
	in statistical efficiency from smoothing methods compared to using
	the peristimulus\&ndash;time histogram (PSTH), and we also demonstrate
	a new method of adaptive smoothing known as Bayesian adaptive regression
	splines (DiMatteo I, Genovese C R and Kass R E 2001 Biometrika 88
	1055--71). We briefly review additional applications of smoothing
	with non-Poisson processes and in the joint PSTH for a pair of neurons.},
  discloc = {/media/usbdisk-1/PaperPDF/Spike_Train_Analysis/KassEtAl_2003.pdf},
  file = {KassEtAl_2003.pdf:Spike_Train_Analysis/KassEtAl_2003.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://www.stat.cmu.edu/~kass/papers/smooth.pdf}
}

@ARTICLE{KimeldorfWahba_1971,
  author = {George Kimeldorf and Grace Wahba},
  title = {Some results on Tchebycheffian Spline Functions},
  journal = {J. Mathematical Analysis and Applications},
  year = {1971},
  volume = {33},
  pages = {82-95},
  number = {1},
  note = {Available at: \url{http://www.stat.wisc.edu/~wahba/ftp1/oldie/kw71.pdf}},
  __markedentry = {[xtof]},
  file = {KimeldorfWahba_1971.pdf:SmoothAndKernel/KimeldorfWahba_1971.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://www.stat.wisc.edu/~wahba/ftp1/oldie/kw71.pdf}
}

@ARTICLE{LEcuyerLeydold_2005,
  author = {Pierre L'Ecuyer and Josef Leydold},
  title = {rstream: Streams of random numbers for stochastic simulation},
  journal = {R News},
  year = {2005},
  volume = {5},
  pages = {16--20},
  number = {2},
  month = {November},
  note = {Available from: \url{http://CRAN.R-project.org/doc/Rnews/}},
  __markedentry = {[xtof]},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://CRAN.R-project.org/doc/Rnews/}
}

@ARTICLE{LEcuyerEtAl_2002,
  author = {Pierre L'Ecuyer and Richard Simard and E. Jack Chen and W. David
	Kelton},
  title = {An Objected-Oriented Random-Number Package with Many Long Streams
	and Substreams},
  journal = {Operations Research},
  year = {2002},
  volume = {50},
  pages = {1073--1075},
  number = {6},
  note = {Available at: \url{http://www.iro.umontreal.ca/~lecuyer/myftp/papers/streams00.pdf}},
  __markedentry = {[xtof]},
  abstract = {Multiple independent streams of random numbers are often required
	in simulation studies, for instance, to facilitate synchronization
	for variance-reduction purposes, and for making independent replications.
	A portable set of software utilities is described for uniform randomnumber
	generation. It provides for multiple generators (streams) running
	simultaneously, and eachgenerator (stream) has its sequence of numbers
	partitioned into many long disjoint contiguous substreams. The basic
	underlying generator for this implementation is a combined multiple-recursive
	generator withperiod lengthof approximately 2191, proposed by L?Ecuyer
	(1999a). A C++ interface is described here. Portable implementations
	are available in C, C++, and Java via the online companion to this
	paper on the Operations Research Web site. <http://or.pubs.informs.org/pages/collect.html>.},
  file = {:MonteCarlo_RandomNumbers/LEcuyerEtAl_2002.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.08.15},
  url = {http://www.iro.umontreal.ca/~lecuyer/myftp/papers/streams00.pdf}
}

@ARTICLE{Lecoutre_2003,
  author = {Eric Lecoutre},
  title = {The {R2HTML} Package},
  journal = {R News},
  year = {2003},
  volume = {3},
  pages = {33--36},
  number = {3},
  month = {December},
  note = {Available from: \url{http://cran.r-project.org/doc/Rnews/Rnews_2003-3.pdf}},
  __markedentry = {[xtof]},
  file = {Rnews_2003-3.pdf:http\://CRAN.R-project.org/doc/Rnews/Rnews_2003-3.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://CRAN.R-project.org/doc/Rnews/}
}

@MANUAL{Leydold_2007,
  title = {rstream: Streams of random numbers},
  author = {Joseph Leydold},
  year = {2007},
  note = {R package version 1.2.2},
  __markedentry = {[xtof]},
  owner = {xtof},
  timestamp = {2008.08.15},
  url = {http://statistik.wu-wien.ac.at/arvag/}
}

@BOOK{Lindsey_2004,
  title = {Introduction to {A}pplied {S}tatistics: {A} {M}odelling {A}pproach},
  publisher = {Oxford University Press},
  year = {2004},
  author = {Lindsey, J.K.},
  __markedentry = {[xtof]},
  isbn = {0-19-852895-7},
  owner = {xtof},
  timestamp = {2008.03.14}
}

@BOOK{Monahan_2001,
  title = {Numerical {M}ethods of {S}tatistics},
  publisher = {Cambridge University Press},
  year = {2001},
  author = {Monahan, John F.},
  series = {Cambridge Series in Statistical and Probabilistic Mathematics},
  edition = {First},
  __markedentry = {[xtof]},
  owner = {xtof},
  timestamp = {2008.03.14}
}

@UNPUBLISHED{Murrell_2008,
  author = {Paul Murrell},
  title = {Introduction to Data Technologies},
  note = {Available at: \url{http://www.stat.auckland.ac.nz/~paul/ItDT/}},
  month = {aug},
  year = {2008},
  __markedentry = {[xtof]},
  file = {:R_stuff/Murrell_2008.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.08.29},
  url = {http://www.stat.auckland.ac.nz/~paul/ItDT/}
}

@ARTICLE{Nychka_1988,
  author = {Nychka, Douglas},
  title = {Bayesian Confidence Intervals for Smoothing Splines},
  journal = {Journal of the American Statistical Association},
  year = {1988},
  volume = {83},
  pages = {1134--1143},
  number = {404},
  month = {dec},
  __markedentry = {[xtof]},
  abstract = {The frequency properties of Wahba's Bayesian confidence intervals
	for smoothing splines are investigated by a large-sample approximation
	and by a simulation study. When the coverage probabilities for these
	pointwise confidence intervals are averaged across the observation
	points, the average coverage probability (ACP) should be close to
	the nomial level. From a frequency point of view, this agreement
	occurs because the average posterior variance for the spline is similar
	to a consistent estimate of the average squared error and because
	the average squared bias is a modest fraction of the total average
	squared error. These properties are independent of the Bayesian assumptions
	used to derive this confidence procedure, and they explain why the
	ACP is accurate for functions that are much smoother than the sample
	paths prescribed by the prior. This analysis accounts for the choice
	of the smoothing parameter (bandwidth) using cross-validation. In
	the case of natural splines an adaptive method for avoiding boundary
	effects is considered. The main disadvantage of this approach is
	that these confidence intervals are only valid in an average sense
	and may not be reliable if only evaluated at peaks or troughs in
	the estimate.},
  copyright = {Copyright 1988 American Statistical Association},
  file = {Nychka_1988.pdf:SmoothAndKernel/Nychka_1988.pdf:PDF},
  group = {Theory and Methods},
  issn = {0162-1459},
  jstor_articletype = {Full Length Article},
  jstor_date = {198812},
  jstor_formatteddate = {Dec., 1988},
  keywords = {Boundary effects, Cross-validation, Nonparametric regression, Smoothing
	parameter},
  owner = {xtof},
  publisher = {American Statistical Association},
  timestamp = {2008.03.14},
  url = {http://links.jstor.org/sici?sici=0162-1459%28198812%2983%3A404%3C1134%3ABCIFSS%3E2.0.CO%3B2-2}
}

@ARTICLE{OSullivan_1986,
  author = {O'Sullivan, Finbarr},
  title = {A Statistical Perspective on Ill-Posed Inverse Problems},
  journal = {Statistical Science},
  year = {1986},
  volume = {1},
  pages = {502--518},
  number = {4},
  month = {nov},
  __markedentry = {[xtof]},
  abstract = {Ill-posed inverse problems arise in many branches of science and engineering.
	In the typical situation one is interested in recovering a whole
	function given a finite number of noisy measurements on functionals.
	Performance characteristics of an inversion algorithm are studied
	via the mean square error which is decomposed into bias and variability.
	Variability calculations are often straightforward, but useful bias
	measures are more difficult to obtain. An appropriate definition
	of what geophysicists call the Backus-Gilbert averaging kernel leads
	to a natural way of measuring bias characteristics. Moreover, the
	ideas give rise to some important experimental design criteria. It
	can be shown that the optimal inversion algorithms are methods of
	regularization procedures, but to completely specify these algorithms
	the signal to noise ratio must be supplied. Statistical approaches
	to the empirical determination of the signal to noise ratio are discussed;
	cross-validation and unbiased risk methods are reviewed; and some
	extensions, which seem particularly appropriate in the inverse problem
	context, are indicated. Linear and nonlinear examples from medicine,
	meteorology, and geophysics are used for illustration.},
  copyright = {Copyright 1986 Institute of Mathematical Statistics},
  file = {OSullivan_1986.pdf:SmoothAndKernel/OSullivan_1986.pdf:PDF},
  issn = {0883-4237},
  jstor_articletype = {Full Length Article},
  jstor_date = {198611},
  jstor_formatteddate = {Nov., 1986},
  keywords = {Averaging kernel, B-splines, cross-validation, experimental design,
	mean square error, reservoir engineering, stereology, satellite meteorology},
  owner = {xtof},
  publisher = {Institute of Mathematical Statistics},
  timestamp = {2008.03.14},
  url = {http://links.jstor.org/sici?sici=0883-4237%28198611%291%3A4%3C502%3AASPOII%3E2.0.CO%3B2-B}
}

@ARTICLE{Ogata_1988,
  author = {Ogata, Yosihiko},
  title = {Statistical {M}odels for {E}arthquake {O}ccurrences and {R}esidual
	{A}nalysis for {P}oint {P}rocesses},
  journal = {Journal of the American Statistical Association},
  year = {1988},
  volume = {83},
  pages = {9--27},
  number = {401},
  __markedentry = {[xtof]},
  abstract = {This article discusses several classes of stochastic models for the
	origin times and magnitudes of earthquakes. The models are compared
	for a Japanese data set for the years 1885-1980 using likelihood
	methods. For the best model, a change of time scale is made to investigate
	the deviation of the data from the model. Conventional graphical
	methods associated with stationary Poisson processes can be used
	with the transformed time scale. For point processes, effective use
	of such residual analysis makes it possible to find features of the
	data set that are not captured in the model. Based on such analyses,
	the utility of seismic quiescence for the prediction of a major earthquake
	is investigated.},
  file = {Ogata_1988.pdf:Statistics/Ogata_1988.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://links.jstor.org/sici?sici=0162-1459%28198803%2983%3A401%3C9%3ASMFEOA%3E2.0.CO%3B2-1}
}

@MANUAL{Peng_2007,
  title = {cacheSweave: Tools for caching Sweave computations},
  author = {Roger D. Peng},
  year = {2007},
  note = {R package version 0.4-3},
  __markedentry = {[xtof]},
  owner = {xtof},
  timestamp = {2008.09.03}
}

@ARTICLE{PerkelEtAl_1967,
  author = {Perkel, D. H. and Gerstein, G. L. and Moore, G. P.},
  title = {Neuronal spike trains and stochastic point processes. {I} the single
	spike train},
  journal = {Biophys. J.},
  year = {1967},
  volume = {7},
  pages = {391--418},
  note = {Available from: \url{http://www.pubmedcentral.nih.gov/articlerender.fcgi?tool=pubmed&pubmedid=4292791}},
  __markedentry = {[xtof]},
  abstract = {In a growing class of neurophysiological experiments, the train of
	impulses ("spikes") produced by a nerve cell is subjected to statistical
	treatment involving the time intervals between spikes. The statistical
	techniques available for the analysis of single spike trains are
	described and related to the underlying mathematical theory, that
	of stochastic point processes, i.e., of stochastic processes whose
	realizations may be described as series of point events occurring
	in time, separated by random intervals. For single stationary spike
	trains, several orders of complexity of statistical treatment are
	described; the major distinction is that between statistical measures
	that depend in an essential way on the serial order of interspike
	intervals and those that are order-independent. The interrelations
	among the several types of calculations are shown, and an attempt
	is made to ameliorate the current nomenclatural confusion in this
	field. Applications, interpretations, and potential difficulties
	of the statistical techniques are discussed, with special reference
	to types of spike trains encountered experimentally. Next, the related
	types of analysis are described for experiments which involve repeated
	presentations of a brief, isolated stimulus. Finally, the effects
	of nonstationarity, e.g. long-term changes in firing rate, on the
	various statistical measures are discussed. Several commonly observed
	patterns of spike activity are shown to be differentially sensitive
	to such changes. A companion paper covers the analysis of simultaneously
	observed spike trains.},
  discloc = {file:///mnt/WD_Passport/PaperPDF/Spike_Train_Analysis/PerkelEtAl_1967.pdf},
  eprint = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?tool=pubmed&pubmedid=4292791},
  file = {PerkelEtAl_1967.pdf:Spike_Train_Analysis/PerkelEtAl_1967.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?tool=pubmed&pubmedid=4292791}
}

@ARTICLE{PerkelEtAl_1967b,
  author = {Perkel, D. H. and Gerstein, G. L. and Moore, G. P.},
  title = {Neuronal spike trains and stochastic point processes. {II} simultaneous
	spike trains},
  journal = {Biophys. J.},
  year = {1967},
  volume = {7},
  pages = {419--440},
  note = {Available from: \url{http://www.pubmedcentral.nih.gov/articlerender.fcgi?tool=pubmed&pubmedid=4292792}},
  __markedentry = {[xtof]},
  abstract = {The statistical analysis of two simultaneously observed trains of
	neuronal spikes is described, using as a conceptual framework the
	theory of stochastic point processes. The first statistical question
	that arises is whether the observed trains are independent; statistical
	techniques for testing independence are developed around the notion
	that, under the null hypothesis, the times of spike occurrence in
	one train represent random instants in time with respect to the other.
	If the null hypothesis is rejected--if dependence is attributed to
	the trains--the problem then becomes that of characterizing the nature
	and source of the observed dependencies. Statistical signs of various
	classes of dependencies, including direct interaction and shared
	input, are discussed and illustrated through computer simulations
	of interacting neurons. The effects of nonstationarities on the statistical
	measures for simultaneous spike trains are also discussed. For two-train
	comparisons of irregularly discharging nerve cells, moderate nonstationarities
	are shown to have little effect on the detection of interactions.
	Combining repetitive stimulation and simultaneous recording of spike
	trains from two (or more) neurons yields additional clues as to possible
	modes of interaction among the monitored neurons; the theory presented
	is illustrated by an application to experimentally obtained data
	from auditory neurons. A companion paper covers the analysis of single
	spike trains.},
  discloc = {file:///mnt/WD_Passport/PaperPDF/Spike_Train_Analysis/PerkelEtAl_1967b.pdf},
  eprint = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?tool=pubmed&pubmedid=4292792},
  file = {PerkelEtAl_1967b.pdf:Spike_Train_Analysis/PerkelEtAl_1967b.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?tool=pubmed&pubmedid=4292792}
}

@MANUAL{Pouzat_2006,
  title = {The New SpikeOMatic Tutorial},
  author = {Christophe Pouzat},
  year = {2006},
  note = {Available from: \url{http://www.biomedicale.univ-paris5.fr/physcerv/C_Pouzat/Data_folder/newSOMtutorial.pdf}},
  __markedentry = {[xtof]},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://www.biomedicale.univ-paris5.fr/physcerv/C_Pouzat/Data_folder/newSOMtutorial.pdf}
}

@MANUAL{R-2.7.2,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Development Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2008},
  note = {{ISBN} 3-900051-07-0},
  __markedentry = {[xtof]},
  owner = {xtof},
  timestamp = {2008.09.01},
  url = {http://www.R-project.org}
}

@TECHREPORT{RossiniEtAl_2003,
  author = {Rossini, Anthony and Tierney, Luke and Li, Na},
  title = {Simple {P}arallel {S}tatistical {C}omputing in {R}},
  institution = {University of Washington},
  year = {2003},
  type = {UW Biostatistics Working Paper Series},
  number = {193},
  note = {Available from: \url{http://www.bepress.com/uwbiostat/paper193/}},
  __markedentry = {[xtof]},
  abstract = {Theoretically, many modern statistical procedures are trivial to parallelize.
	However, practical deployment of a parallelized implementation which
	is robust and reliably runs on different computational cluster configurations
	and environments is far from trivial. We present a framework for
	the R statistical computing language that provides a simple yet powerful
	programming interface to a computational cluster. This interface
	allows the development of R functions that distribute independent
	computations across the nodes of the computational cluster. The resulting
	framework allows statisticians to obtain significant speed-ups for
	some computations at little additional development cost. The particular
	implementation can be deployed in heterogeneous computing environments.},
  file = {RossiniEtAl_2003.pdf:/media/usbdisk-1/PaperPDF/Software/RossiniEtAl_2003.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://www.bepress.com/uwbiostat/paper193/}
}

@MANUAL{TierneyEtAl_,
  title = {snow: Simple Network of Workstations},
  author = {Luke Tierney and A. J. Rossini and Na Li and H. Sevcikova},
  note = {R package version 0.3-3},
  __markedentry = {[xtof]},
  owner = {xtof},
  timestamp = {2008.08.15}
}

@ARTICLE{TurnbullEtAl_2005,
  author = {Lon Turnbull and Emese Dian and Guenter Gross},
  title = {The string method of burst identification in neuronal spike trains.},
  journal = {J Neurosci Methods},
  year = {2005},
  volume = {145},
  pages = {23--35},
  number = {1-2},
  month = {Jun},
  __markedentry = {[xtof]},
  abstract = {The activity state of neuronal networks can be characterized by the
	spatial-temporal grouping of their action potentials given a sufficiently
	large simultaneous recording sample. A sequence of action potentials
	(spike train) often has high frequency spike episodes that are generally
	called bursts. However, bursts are difficult to quantify and require
	operational definitions that reflect the type of activity and the
	interest of the experimenter. This paper presents a simple method
	for defining bursts as strings of spikes with only two parameters:
	a minimum number of spikes per burst and a maximum interspike interval.
	These two values represent a simple parameterization that is adequate
	for the description of temporal grouping in spike trains. Because
	this method has a minimal computation time, it allows implementation
	of burst analysis in real-time, including statistical changes in
	burst variables, histograms of burst types, and patterns in combinations
	of burst variables.},
  doi = {10.1016/j.jneumeth.2004.11.020},
  file = {TurnbullEtAl_2005.pdf:Spike_Train_Analysis/TurnbullEtAl_2005.pdf:PDF},
  keywords = {Action Potentials; Animals; Cells, Cultured; Humans; Models, Neurological;
	Neural Networks (Computer); Neurons},
  owner = {xtof},
  pii = {S0165-0270(04)00429-7},
  pmid = {15922023},
  timestamp = {2008.03.14},
  url = {http://dx.doi.org/10.1016/j.jneumeth.2004.11.020}
}

@ARTICLE{VenturaEtAl_2002,
  author = {Ventura, Valerie and Carta, Roberto and Kass, Robert E. and Gettner,
	Sonya N. and Olson, Carl R.},
  title = {Statistical analysis of temporal evolution in single-neuron firing
	rates},
  journal = {Biostat},
  year = {2002},
  volume = {3},
  pages = {1--20},
  number = {1},
  note = {Available from: \url{http://www.stat.cmu.edu/~kass/papers/temporal.pdf}},
  __markedentry = {[xtof]},
  abstract = {A fundamental methodology in neurophysiology involves recording the
	electrical signals associated with individual neurons within brains
	of awake behaving animals. Traditional statistical analyses have
	relied mainly on mean firing rates over some epoch (often several
	hundred milliseconds) that are compared across experimental conditions
	by analysis of variance. Often, however, the time course of the neuronal
	firing patterns is of interest, and a more refined procedure can
	produce substantial additional information. In this paper we compare
	neuronal firing in the supplementary eye field of a macaque monkey
	across two experimental conditions. We take the electrical discharges,
	or spikes', to be arrivals in a inhomogeneous Poisson process and
	then model the firing intensity function using both a simple parametric
	form and more flexible splines. Our main interest is in making inferences
	about certain characteristics of the intensity, including the timing
	of the maximal firing rate. We examine data from 84 neurons individually
	and also combine results into a hierarchical model. We use Bayesian
	estimation methods and frequentist significance tests based on a
	nonparametric bootstrap procedure. We are thereby able to conclude
	that a substantial fraction of the neurons exhibit important temporal
	differences in firing intensity across the two conditions, and we
	quantify the effect across the population of neurons.},
  discloc = {/media/usbdisk-1/PaperPDF/Spike_Train_Analysis/VenturaEtAl_2002.pdf},
  eprint = {http://biostatistics.oupjournals.org/cgi/reprint/3/1/1.pdf},
  file = {VenturaEtAl_2002.pdf:Spike_Train_Analysis/VenturaEtAl_2002.pdf:PDF},
  keywords = {Bayesian methods; Bootstrap hypothesis testing; Functional data analysis;
	Inhomogeneous poisson process; Kernel smoothing; Regression splines},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://biostatistics.oupjournals.org/cgi/content/abstract/3/1/1}
}

@BOOK{Wahba_1990,
  title = {Spline Models for Observational Data},
  publisher = {SIAM},
  year = {1990},
  author = {Grace Wahba},
  __markedentry = {[xtof]},
  owner = {xtof},
  timestamp = {2008.03.14}
}

@ARTICLE{Wahba_1983,
  author = {Wahba, Grace},
  title = {Bayesian "Confidence Intervals" for the Cross-Validated Smoothing
	Spline},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  year = {1983},
  volume = {45},
  pages = {133--150},
  number = {1},
  __markedentry = {[xtof]},
  abstract = {We consider the model $Y(t_i) = g(t_i) = \epsilon_i, i = 1, 2,\ldots,
	n$, where $g(t), t \in \lbrack 0, 1\rbrack$ is a smooth function
	and the $\{\epsilon_i\}$ are independent $N(0, \sigma^2)$ errors
	with $\sigma^2$ unknown. The cross-validated smoothing spline can
	be used to estimate $g$ non-parametrically from observations on $Y(t_i),
	i = 1, 2,\ldots, n$, and the purpose of this paper is to study confidence
	intervals for this estimate. Properties of smoothing splines as Bayes
	estimates are used to derive confidence intervals based on the posterior
	covariance functiion of the estimate. A small Monte Carlo study with
	the cubic smoothing spline is carried out to suggest by example to
	what extent the resulting 95 per cent confidence intervals can be
	expected to cover about 95 per cent of the true (but in practice
	unknown) values of $g(t_i), i = 1, 2,\ldots, n$. The method was also
	applied to one example of a two-dimensional thin plate smoothing
	spline. An asymptotic theoretical argument is presented to explain
	why the method can be expected to work on fixed smooth functions
	(like those tried), which are "smoother" than the sample functions
	from the prior distributions on which the confidence interval theory
	is based.},
  copyright = {Copyright 1983 Royal Statistical Society},
  file = {Wahba_1983.pdf:SmoothAndKernel/Wahba_1983.pdf:PDF},
  issn = {0035-9246},
  jstor_articletype = {Full Length Article},
  jstor_date = {1983},
  jstor_formatteddate = {1983},
  keywords = {Spline Smoothing, Cross-Validation, Confidence Intervals},
  owner = {xtof},
  publisher = {Royal Statistical Society},
  timestamp = {2008.03.14},
  url = {http://links.jstor.org/sici?sici=0035-9246%281983%2945%3A1%3C133%3AB%22IFTC%3E2.0.CO%3B2-B}
}

@ARTICLE{WallstromEtAl_2008,
  author = {Garrick Wallstrom and Jeffrey Liebner and Robert E. Kass},
  title = {An {I}mplementation of {B}ayesian {A}daptive {R}egression {S}plines
	({BARS}) in {C} with {S} and {R} {W}rappers},
  journal = {Journal of Statistical Software},
  year = {2007},
  volume = {26},
  pages = {1--21},
  number = {1},
  month = {2},
  __markedentry = {[xtof]},
  abstract = {BARS (DiMatteo, Genovese, and Kass 2001) uses the powerful reversible-jump
	MCMC engine to perform spline-based generalized nonparametric regression.
	It has been shown to work well in terms of having small mean-squared
	error in many examples (smaller than known competitors), as well
	as producing visually-appealing fits that are smooth (filtering out
	high-frequency noise) while adapting to sudden changes (retaining
	high-frequency signal). However, BARS is computationally intensive.
	The original implementation in S was too slow to be practical in
	certain situations, and was found to handle some data sets incorrectly.
	We have implemented BARS in C for the normal and Poisson cases, the
	latter being important in neurophysiological and other point-process
	applications. The C implementation includes all needed subroutines
	for fitting Poisson regression, manipulating B-splines (using code
	created by Bates and Venables), and finding starting values for Poisson
	regression (using code for density estimation created by Kooperberg).
	The code utilizes only freely-available external libraries (LAPACK
	and BLAS) and is otherwise self-contained. We have also provided
	wrappers so that BARS can be used easily within S or R.},
  accepted = {2007-02-20},
  bibdate = {2007-02-20},
  coden = {JSSOBK},
  day = {20},
  file = {:SmoothAndKernel/WallstromEtAl_2008.pdf:PDF;barsP.tar.gz\: barsP source
	code:http\://www.jstatsoft.org/v26/i01/supp/2:URL;barsN.tar.gz\:
	barsN source code:http\://www.jstatsoft.org/v26/i01/supp/1:URL},
  issn = {1548-7660},
  owner = {xtof},
  submitted = {2004-06-25},
  timestamp = {2008.03.23},
  url = {http://www.jstatsoft.org/v26/i01}
}

@ARTICLE{XiangWahba_1996,
  author = {Dong Xiang and Grace Wahba},
  title = {A GENERALIZED APPROXIMATE CROSS VALIDATION FOR SMOOTHING SPLINES
	WITH NON-GAUSSIAN DATA},
  journal = {Statistica Sinica},
  year = {1996},
  volume = {6},
  pages = {675--692},
  note = {Available at: \url{http://www3.stat.sinica.edu.tw/statistica/j6n3/j6n312/j6n312.htm}},
  __markedentry = {[xtof]},
  abstract = {In this paper, we propose a Generalized Approximate Cross Validation
	(GACV) function for estimating the smoothing parameter in the penalized
	log likelihood regression problem with non-Gaussian data. This GACV
	is obtained by, first, obtaining an approximation to the leaving-out-one
	function based on the negative log likelihood, and then, in a step
	reminiscent of that used to get from leaving-out-one cross validation
	to GCV in the Gaussian case, we replace diagonal elements of certain
	matrices by 1/n times the trace. A numerical simulation with Bernoulli
	data is used to compare the smoothing parameter ? chosen by this
	approximation procedure with the ? chosen from the two most often
	used algorithms based on the generalized cross validation procedure
	(O'Sullivan et al. (1986), Gu (1990, 1992)). In the examples here,
	the GACV estimate produces a better fit of the truth in term of minimizing
	the Kullback-Leibler distance. Figures suggest that the GACV curve
	may be an approximately unbiased estimate of the Kullback-Leibler
	distance in the Bernoulli data case; however, a theoretical proof
	is yet to be found.},
  file = {XiangWahba_1996.pdf:SmoothAndKernel/XiangWahba_1996.pdf:PDF},
  keywords = {Generalized Approximate Cross Validation; generalized cross validation;
	Kullback-Leibler distance; penalized likelihood regression; smoothing
	spline},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://www3.stat.sinica.edu.tw/statistica/j6n3/j6n312/j6n312.htm}
}

@comment{jabref-meta: selector_publisher:}

@comment{jabref-meta: selector_author:}

@comment{jabref-meta: selector_journal:}

@comment{jabref-meta: selector_keywords:}

